static const char gN64FragmentLibrary[] =
"int2 imix(int2 a, int2 b, bool2 c)\n"
"{\n"
"	return int2(lerp(float2(a), float2(b), float2(c)));\n"
"}\n"
"\n"
"// coord:  10.5\n"
"// return: 10.5\n"
"int2 shift(int2 coord, float2 shift_scale)\n"
"{\n"
"	return int2(float2(coord) * shift_scale);\n"
"}\n"
"\n"
"// Clamp a UV coord when point sampling.\n"
"// coord:  10.5\n"
"// return: 10.0, frac (0.5)\n"
"int2 clampPoint(int2 coord, int2 tile_tl, int2 tile_br, bool2 clamp_enable)\n"
"{\n"
"	int2 coord_clamped = clamp(coord, tile_tl<<3, tile_br<<3);\n"
"	int2 coord_out     = imix(coord, coord_clamped, clamp_enable);\n"
"\n"
"	// NB: discard fractional bits.\n"
"	int2 coord_relative = ((coord_out>>3) - tile_tl) >> 2;\n"
"	return coord_relative;\n"
"}\n"
"\n"
"// coord:  10.5\n"
"// return: 10.0, frac (0.5)\n"
"int2 clampBilinear(int2 coord, int2 tile_tl, int2 tile_br, bool2 clamp_enable, out int2 frac)\n"
"{\n"
"	int2 tl = tile_tl<<3;\n"
"	int2 br = tile_br<<3;\n"
"\n"
"	int2 coord_clamped = clamp(coord, tl, br);\n"
"	int2 coord_out     = imix(coord, coord_clamped, clamp_enable);\n"
"\n"
"	// NB: retain fractional bits.\n"
"	int2 coord_relative = coord_out - (tile_tl << 3);\n"
"\n"
"	frac = coord_relative & 0x1f;\n"
"	return coord_relative >> 5;\n"
"}\n"
"\n"
"bool2 notEqual(int2 x, int2 y)\n"
"{\n"
"	return bool2(x.x != y.x, x.y != y.y);\n"
"}\n"
"\n"
"// coord:  10.0\n"
"// return: 10.0\n"
"int2 mask(int2 coord, int2 mirror_bits, int2 mask_bits)\n"
"{\n"
"	bool2 mirror = notEqual(coord & mirror_bits, int2(0,0));\n"
"	coord = imix(coord, ~coord, mirror);	// Invert the bits if mirroring.\n"
"	coord &= mask_bits;\n"
"	return coord;\n"
"}\n"
"\n"
"// This is higher quality bilinear filter than the n64 hardware used, and probably cheaper.\n"
"float4 bilinear(float4 col_00, float4 col_01, float4 col_10, float4 col_11, int2 frac)\n"
"{\n"
"	float2 fracf = float2(frac) / 32.f;\n"
"\n"
"	float4 a = lerp(col_00, col_10, fracf.x);\n"
"	float4 b = lerp(col_01, col_11, fracf.x);\n"
"	return lerp(a, b, fracf.y);\n"
"}\n"
"\n"
"float4 bilinear_n64(float4 col_00, float4 col_01, float4 col_10, float4 col_11, int2 frac)\n"
"{\n"
"	bool upper     = frac.x + frac.y >= 0x20;\n"
"	bool4 uppersel = bool4(upper, upper, upper, upper);\n"
"\n"
"	// Pick either the bottom-left or top-right texel, and lerp along the edges.\n"
"	float4 col0  = lerp(col_00, col_11, uppersel);\n"
"	float4 col1  = lerp(col_10, col_01, uppersel);\n"
"	float4 col2  = lerp(col_01, col_10, uppersel);\n"
"	float2 fracf = imix(frac, 0x20 - frac, uppersel.xy) / 32.f;\n"
"\n"
"	float4 col = col0 + (fracf.x * (col1 - col0)) + (fracf.y * (col2 - col0));\n"
"	return clamp(col, 0.f, 1.f);\n"
"}\n"
"\n"
"float4 fetchBilinear(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"				   int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"				   sampler2D tex, float2 tex_scale)\n"
"{\n"
"	int2 frac;\n"
"	int2 uv0 = int2(st_in);\n"
"	uv0 = shift(uv0, shift_scale);\n"
"	uv0 = clampBilinear(uv0, tile_tl, tile_br, clamp_enable, /*out */frac);\n"
"\n"
"	int2 uv1 = uv0 + int2(1,1);\n"
"\n"
"	uv0 = mask(uv0, mirror_bits, mask_bits);\n"
"	uv1 = mask(uv1, mirror_bits, mask_bits);\n"
"\n"
"	float4 col_00  = texelFetch(tex, int2(uv0.x, uv0.y), 0);\n"
"	float4 col_01  = texelFetch(tex, int2(uv0.x, uv1.y), 0);\n"
"	float4 col_10  = texelFetch(tex, int2(uv1.x, uv0.y), 0);\n"
"	float4 col_11  = texelFetch(tex, int2(uv1.x, uv1.y), 0);\n"
"\n"
"	return bilinear(col_00, col_01, col_10, col_11, frac);\n"
"}\n"
"\n"
"float4 fetchBilinearClampedCommon(\n"
"					float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"					int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"					sampler2D tex, float2 tex_scale, int2 bilerp_wrap_enable)\n"
"{\n"
"	int2 frac;\n"
"	int2 uv0 = int2(st_in);\n"
"	uv0 = shift(uv0, shift_scale);\n"
"	uv0 = clampBilinear(uv0, tile_tl, tile_br, clamp_enable, /*out */frac);\n"
"\n"
"	int2 uv1 = uv0 + int2(1,1);\n"
"\n"
"	uv0 = mask(uv0, mirror_bits, mask_bits);\n"
"	uv1 = mask(uv1, mirror_bits, mask_bits);\n"
"\n"
"	// If uv1 has wrapped (less than uv0) then set to zero\n"
"	// (bilerp_wrap_enable is a bitmask - if 0, the fractional bits are zeroed)\n"
"	frac = imix(frac, frac & bilerp_wrap_enable, lessThan(uv1, uv0));\n"
"\n"
"	float4 col_00  = texelFetch(tex, int2(uv0.x, uv0.y), 0);\n"
"	float4 col_01  = texelFetch(tex, int2(uv0.x, uv1.y), 0);\n"
"	float4 col_10  = texelFetch(tex, int2(uv1.x, uv0.y), 0);\n"
"	float4 col_11  = texelFetch(tex, int2(uv1.x, uv1.y), 0);\n"
"\n"
"	return bilinear(col_00, col_01, col_10, col_11, frac);\n"
"}\n"
"\n"
"float4 fetchBilinearClampedS(\n"
"					float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"					int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"					sampler2D tex, float2 tex_scale)\n"
"{\n"
"	return fetchBilinearClampedCommon(\n"
"		st_in, shift_scale, mirror_bits,mask_bits,\n"
"		tile_tl, tile_br, clamp_enable, tex, tex_scale, int2(0, -1));\n"
"}\n"
"\n"
"float4 fetchBilinearClampedT(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"				   int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"				   sampler2D tex, float2 tex_scale)\n"
"{\n"
"	return fetchBilinearClampedCommon(\n"
"		st_in, shift_scale, mirror_bits,mask_bits,\n"
"		tile_tl, tile_br, clamp_enable, tex, tex_scale, int2(-1, 0));\n"
"}\n"
"\n"
"float4 fetchBilinearClampedST(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"				   int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"				   sampler2D tex, float2 tex_scale)\n"
"{\n"
"	return fetchBilinearClampedCommon(\n"
"		st_in, shift_scale, mirror_bits,mask_bits,\n"
"		tile_tl, tile_br, clamp_enable, tex, tex_scale, int2(0, 0));\n"
"}\n"
"\n"
"// Point sample\n"
"float4 fetchPoint(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"				int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"				sampler2D tex, float2 tex_scale)\n"
"{\n"
"	int2 uv = int2(st_in);\n"
"	uv = shift(uv, shift_scale);\n"
"	uv = clampPoint(uv, tile_tl, tile_br, clamp_enable);\n"
"	uv = mask(uv, mirror_bits, mask_bits);\n"
"\n"
"	return texelFetch(tex, uv, 0);\n"
"}\n"
"\n"
"// For cycle type Copy - there is no clamping.\n"
"float4 fetchCopy(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"			  int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"			  sampler2D tex, float2 tex_scale)\n"
"{\n"
"	int2 uv = int2(st_in);\n"
"	uv = shift(uv, shift_scale);\n"
"	uv = (((uv>>3) - tile_tl) >> 2) & 0x1fff;\n"
"	uv = mask(uv, mirror_bits, mask_bits);\n"
"\n"
"	return texelFetch(tex, uv, 0);\n"
"}\n"
"\n"
"// This just uses regular OpenGL texture filtering.\n"
"// It doesn't handle shift/scale/mirror etc.\n"
"float4 fetchSimple(float2 st_in, float2 shift_scale, int2 mirror_bits, int2 mask_bits,\n"
"				 int2 tile_tl, int2 tile_br, bool2 clamp_enable,\n"
"				 sampler2D tex, float2 tex_scale)\n"
"{\n"
"	int2 uv = int2(st_in);\n"
"	uv = shift(uv, shift_scale);\n"
"\n"
"	float2 uvf = (uv - (tile_tl<<3)) * (tex_scale / 32.f);\n"
"	return texture(tex, uvf);\n"
"}\n"
;
